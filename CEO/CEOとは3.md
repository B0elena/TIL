# ７．基本的なSEO対策2：きちんとインデックスさせる
Googleの場合、検索順位の決定は以下のような流れで行われる。<br>
クローラー（Googlebot）がウェブページをクロールし、テキスト情報を読み取る<br>
クロールしたウェブページをインデックスする<br>
インデックスしたページの中から検索キーワードとの関連性が高く、評価の高いものを検索結果に表示する<br>
いくらコンテンツをしっかり作り込んでいても、それがGooglebotにクロールされず、また正しくインデックスされなければ検索結果に表示されることはない。

## 1　インデックスとは？
インデックスとは、Googleがウェブサイトをクロールし、サイト情報をデータベースに保存することを言う。<br>
インデックスは一度されればすべての情報が正確に保存されるわけではなく、何度もインデックスを繰り返すことで正確に評価されるようになっていく。<br>
つまり、何度もクロールされる、クロール頻度を高くするということも重要。<br>
インデックス数が多いサイトはそれだけウェブサイトのポテンシャルが大きいと判断されるが、ただ単にインデックスされたページ数が多いだけでは全く意味がない。<br>
コンテンツの重複がなく、しっかりと作りこまれた良質なページが全て正しくインデックスされることでSEO評価が上がる。<br>
競合サイトとのランキングに差がある場合はインデックス数を比較し、大きく開きがある場合は少しずつ近づけていく必要がある。

## 2　低品質コンテンツをインデックスから除外する
低品質コンテンツとは、情報量（文字数）が少なく他のページに比べてそれほど重要ではないページ、またはユーザーに対してあえて検索結果に表示させる必要のないページを指す。<br>
低品質に該当しないページを作ることが基本だが、サイトのコンテンツとしては必要な、情報量が少ないページも存在する。<br>
それら低品質コンテンツに該当しそうなページは「noindex処理」することでインデックスから除外し、サイト全体のインデックスされたページの品質を保つ。

## 3　URL正規化でインデックスページの重複をなくす
GoogleはURLが異なるページは同一のコンテンツでも別ページと判断する。<br>
異なるURLで同一コンテンツがインデックスされてしまうと、ページの評価が分散し順位に影響が出てしまう。<br>
URLの記述違いによる重複インデックスを避けるため、検索エンジンが優先的にインデックスするべきURLをcanonical属性タグを利用して統一させておく必要がある。<br>
この対策を「URLの正規化」と言う。

# ８．基本的なSEO対策3：サイトへクロールしてもらいやすくする
クローラビリティの促進は、ページのインデックスをより早く、より正確にするために重要であり、よくクロールされるサイトほどGoogleはそのサイトを重要であると判断している。

## 1　クローラビリティを促進する（クロール頻度を上げる）ポイント
sitemap.xmlはGoogleにウェブサイト全体のページ構成を伝えるために重要。<br>
まだ作成していない場合は必ず作成し、Google Search Consoleからサイトマップ情報を送信する。

```
注意点
サイトマップは最新情報である必要がある。
コンテンツを新規ページで追加した場合はsitemap.xmlにも追加する。
また、削除したページやnoindex処理したページはsitemap.xmlから外すようにする。
sitemap.xmlのメンテナンスは、手作業ではURLの記述ミスや追加ページ・削除ページの更新漏れが発生しやすく、インデックスの効率が悪くなる。
Webサイトの運用はできればCMS（コンテンツマネジメントシステム）などを利用し、自動でsitemap.xmlの作成やリアルタイムでの更新ができるようにすることで、SEO管理の手間も軽減できる。
```
新規コンテンツの追加やページの修正を行った際には、URL検査ツールで最新のページ情報をすぐにクロールリクエストすることで、インデックスされるまでの待機時間を大きく節約することができる。<br>
※noindex処理をしているページはURL検査ツールでインデックス登録リクエストできません。自然にクロールされるまで待つ必要がある

TOPページなど、頻繁にクロールされるページにリンクを設置することでクロールされやすくなる。<br>
TOPページやカテゴリトップページからリンクを貼る<br>
検索順位で上位表示されているページからリンクを貼る<br>

クロールさせる必要のないページに向けたリンクにはnofollowを入れることで、Googlebotに無駄なクロールをさせず、他の重要なページをクロールさせる手助けとなる。
```
nofollowとは？
「nofollow」は、リンク先にページ評価を受け渡さない、このリンクをたどらない、といった指示を検索エンジンに伝える。
記述例
リンクを行うaタグに対し、rel=”nofollow”を追記する。
<a href=” クロールさせないリンク先URL” rel=”nofollow”>アンカーテキスト</a>
```

「新しく追加されたコンテンツ」などの動的パーツを用意し、<br>
ページが公開されると自動的にリンクされるようなしくみを使うと効果的。

ウェブサイト上のクロールする必要のないページやディレクトリはrobots.txtでクロールをブロックし、Googleのクロールリソースを有効に使う。
```
ブロックするページの例
会員専用画面など認証の必要なページ
検索結果に表示する必要のないページ
注意点
robots.txtもcanonical同様、記述を間違えるとインデックスやクロールに重大な影響がでまる。
robots.txtを記述する場合は、Google Search Consoleの「クロール - robot.txtのテスター」を使って、記載したURLが適切にブロックされているかを必ず確認する。
```

クロールがスムーズに行われるように、適切なHTML構造と論理的な文書構造にする。<br>
また、しっかりしたサーバー環境を用意することも大切。
